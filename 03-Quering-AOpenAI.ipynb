{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d59d527f-1100-45ff-b051-5f7c9029d94d",
   "metadata": {},
   "source": [
    "# Queries with and without Azure OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9a9444-dc90-4fc3-aea7-8ee918301aba",
   "metadata": {},
   "source": [
    "So far, you have your Search Engine loaded **from two different data sources in two diferent indexes**, on this notebook we are going to try some example queries and then use Azure OpenAI service to see if we can get a good answer for the user query.\n",
    "\n",
    "The idea is that a user can ask a question about the dialogues of the TV Show FRIENDS (first datasource index) or about Covid (second datasource/index), and the engine will respond accordingly.\n",
    "\n",
    "This **Multi-Index** demo, mimics the scenario where a company loads multiple type of documents of different types and about completly different topics and the search engine must respond with the most relevant results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f6c7e3-9037-4b1e-ae17-1deaa27b9c08",
   "metadata": {},
   "source": [
    "## Set up variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e50b404-a061-49e7-a3c7-c6eabc98ff0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import urllib\n",
    "import requests\n",
    "import random\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "from IPython.display import display, HTML, Markdown\n",
    "from typing import List\n",
    "from operator import itemgetter\n",
    "\n",
    "# LangChain Imports needed\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from langchain_core.callbacks import CallbackManagerForRetrieverRun\n",
    "from langchain_core.runnables import ConfigurableField\n",
    "\n",
    "\n",
    "# Our own libraries needed\n",
    "from common.prompts import DOCSEARCH_PROMPT_TEXT\n",
    "from common.utils import get_search_results\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"credentials.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f2c22f8-79ab-405c-95e8-77a1978e53bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup the Payloads header\n",
    "headers = {'Content-Type': 'application/json','api-key': os.environ['AZURE_SEARCH_KEY']}\n",
    "params = {'api-version': os.environ['AZURE_SEARCH_API_VERSION']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9297d29b-1f61-4dce-858e-bf4272172dba",
   "metadata": {},
   "source": [
    "## Multi-Index Search queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a46e2d3-298a-4708-83de-9e108b1a117a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Text-based Indexes that we are going to query (from Notebook 01 and 02)\n",
    "index1_name = \"srch-index-files\"\n",
    "index2_name = \"srch-index-csv\"\n",
    "indexes = [index2_name, index1_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c62ebb2-d7be-4bfb-b1ba-4db86c11839a",
   "metadata": {},
   "source": [
    "Try questions that you think might be answered or addressed in the dialogues of Friends, or that can be addressed by medical publications about COVID in 2020-2021. Try comparing the results with the open version of ChatGPT.<br>\n",
    "The idea is that the answers using Azure OpenAI only looks at the information contained on these documents.\n",
    "\n",
    "**Example Questions you can ask**:\n",
    "- Is Chandler ever jealous of Richard?\n",
    "- Who is Mindy?\n",
    "- What happened between Ross and Rachel in Vegas?\n",
    "- What are some examples of reinforcement learning in virus spread?\n",
    "- What are the main risk factors for Covid-19?\n",
    "- What medicine reduces inflamation in the lungs?\n",
    "- Why Covid doesn't affect kids that much compared to adults?\n",
    "- Does chloroquine really works against covid?\n",
    "- Who won the 1994 soccer world cup? # This question should yield no answer if the system is correctly grounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9b53c14-19bd-451f-aa43-7ad27ccfeead",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "QUESTION = \"Is Chandler ever jealous of Richard?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d925eb-7f9c-429e-a62a-4c37d7702caf",
   "metadata": {},
   "source": [
    "### Search on both indexes individually and aggragate results\n",
    "\n",
    "#### **Note**: \n",
    "In order to standarize the indexes, **there must be 6 mandatory fields present on each index**: `id, title, name, location, chunk, chunkVector`. This is so that each document can be treated the same along the code. Also, **all indexes must have a semantic configuration**.\n",
    "\n",
    "We are going to use Hybrid Queries: Text + Vector Search combined for optimal results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faf2e30f-e71f-4533-ab52-27d048b80a89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "Index: srch-index-csv Results Found: 69683, Results Returned: 10\n",
      "200\n",
      "Index: srch-index-files Results Found: 2896, Results Returned: 10\n"
     ]
    }
   ],
   "source": [
    "agg_search_results = dict()\n",
    "k = 10\n",
    "\n",
    "for index in indexes:\n",
    "    search_payload = {\n",
    "        \"search\": QUESTION, # Text query\n",
    "        \"select\": \"id, title, name, location, chunk\",\n",
    "        \"queryType\": \"semantic\",\n",
    "        \"vectorQueries\": [{\"text\": QUESTION, \"fields\": \"chunkVector\", \"kind\": \"text\", \"k\": k}], # Vector query\n",
    "        \"semanticConfiguration\": \"my-semantic-config\",\n",
    "        \"captions\": \"extractive\",\n",
    "        \"answers\": \"extractive\",\n",
    "        \"count\":\"true\",\n",
    "        \"top\": k\n",
    "    }\n",
    "\n",
    "    r = requests.post(os.environ['AZURE_SEARCH_ENDPOINT'] + \"/indexes/\" + index + \"/docs/search\",\n",
    "                     data=json.dumps(search_payload), headers=headers, params=params)\n",
    "    print(r.status_code)\n",
    "\n",
    "    search_results = r.json()\n",
    "    agg_search_results[index]=search_results\n",
    "    print(\"Index:\", index, \"Results Found: {}, Results Returned: {}\".format(search_results['@odata.count'], len(search_results['value'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33018be-350d-4c54-b491-a86bc1cfffb6",
   "metadata": {},
   "source": [
    "#### **Important Note**: \n",
    "You may encounter errors (502) when attempting to search for results IF the indexer is still processing documents. This occurs because the embedding model is heavily utilized by the indexer, hitting its TPM quota. If you experience search errors, please try again or wait until the indexing is complete, which may take several hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "255c40f5-d836-480c-8c68-06a2282c8146",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# agg_search_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fd0fe5-4ee0-42e2-a920-72b93a407389",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Display the top results (from both searches) based on the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e938337-602d-4b61-8141-b8c92a5d91da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Top Answers</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Top Results</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5><a href=\"https://blobstorages37d5t5m5wcyq.blob.core.windows.net/friends/s09/e07/c11.txt?sv=2022-11-02&ss=b&srt=sco&sp=rltfx&se=2025-10-10T11:14:44Z&st=2024-10-10T03:14:44Z&spr=https&sig=SR5VNDrPwrWJX4%2FphBxasF51p1x5Y85bf2Q%2FqcbJYLk%3D\">https://blobstorages37d5t5m5wcyq.blob.core.windows.net/friends/s09/e07/c11.txt</a> - score: 2.36</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Chandler Bing: Oh, yeah, well, poor Richard Y' I can grow a moustache! Monica Geller: Chandler, this is not our problem We've got each other That's all that matters Chandler Bing: Yeah, oh, but I just keep picturing you rolling around with him with your cowboy boots in the air Monica Geller: Cowboy boots? I've never worn cowboy boots in my whole li..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5><a href=\"https://blobstorages37d5t5m5wcyq.blob.core.windows.net/friends/s03/e12/c15.txt?sv=2022-11-02&ss=b&srt=sco&sp=rltfx&se=2025-10-10T11:14:44Z&st=2024-10-10T03:14:44Z&spr=https&sig=SR5VNDrPwrWJX4%2FphBxasF51p1x5Y85bf2Q%2FqcbJYLk%3D\">https://blobstorages37d5t5m5wcyq.blob.core.windows.net/friends/s03/e12/c15.txt</a> - score: 1.92</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "I mean doesn't she have any y'know other stripper moms friends of her own? Ross Geller: You are totally jealous Rachel Green: I'm not jealous All right this is about, umm, people feeling certain things y'know about strippers And y'know, and um, I Ross Geller: Honey, I love you too Rachel Green: Ugh Wait, wait, wait Ross Geller: What?  unknown: nan ..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5><a href=\"https://blobstorages37d5t5m5wcyq.blob.core.windows.net/friends/s06/e25/c05.txt?sv=2022-11-02&ss=b&srt=sco&sp=rltfx&se=2025-10-10T11:14:44Z&st=2024-10-10T03:14:44Z&spr=https&sig=SR5VNDrPwrWJX4%2FphBxasF51p1x5Y85bf2Q%2FqcbJYLk%3D\">https://blobstorages37d5t5m5wcyq.blob.core.windows.net/friends/s06/e25/c05.txt</a> - score: 1.9</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Richard! Joey Tribbiani: R-R-Richard said he wants to marry you?! And-and Chandler's tellin' ya how much he hates marriage?! Monica Geller: That's right Joey Tribbiani: Chandler loves marriage!! Monica Geller: You just told me that he hates marriage! That-that he's a-a complex fellow who's unlikely to take a wife! That-that he's against marriage an..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5><a href=\"https://blobstorages37d5t5m5wcyq.blob.core.windows.net/friends/s06/e25/c01.txt?sv=2022-11-02&ss=b&srt=sco&sp=rltfx&se=2025-10-10T11:14:44Z&st=2024-10-10T03:14:44Z&spr=https&sig=SR5VNDrPwrWJX4%2FphBxasF51p1x5Y85bf2Q%2FqcbJYLk%3D\">https://blobstorages37d5t5m5wcyq.blob.core.windows.net/friends/s06/e25/c01.txt</a> - score: 1.9</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "And I know I probably shouldn't even be here telling you this, I mean you're with Chandler a guy I really like, and if you say he's straight I'll believe you! After seeing ya the other night I knew if I didn't tell ya I'd regret it for the rest of my life Letting you go was the stupidest thing I ever did Monica Geller: Y'know you're really not supp..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5><a href=\"https://blobstorages37d5t5m5wcyq.blob.core.windows.net/friends/s06/e25/c12.txt?sv=2022-11-02&ss=b&srt=sco&sp=rltfx&se=2025-10-10T11:14:44Z&st=2024-10-10T03:14:44Z&spr=https&sig=SR5VNDrPwrWJX4%2FphBxasF51p1x5Y85bf2Q%2FqcbJYLk%3D\">https://blobstorages37d5t5m5wcyq.blob.core.windows.net/friends/s06/e25/c12.txt</a> - score: 1.86</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "my God.  unknown: nan  Monica Geller: Chandler In all my life I never thought I would be so lucky As to...fall in love with my best...my best There's a reason why girls don't do this! Chandler Bing: Okay! Okay! Okay! Oh God, I thought Wait a minute, I-I can do this I thought that it mattered what I said or where I said it Then I realized the only t..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5><a href=\"https://blobstorages37d5t5m5wcyq.blob.core.windows.net/friends/s05/e23/c03.txt?sv=2022-11-02&ss=b&srt=sco&sp=rltfx&se=2025-10-10T11:14:44Z&st=2024-10-10T03:14:44Z&spr=https&sig=SR5VNDrPwrWJX4%2FphBxasF51p1x5Y85bf2Q%2FqcbJYLk%3D\">https://blobstorages37d5t5m5wcyq.blob.core.windows.net/friends/s05/e23/c03.txt</a> - score: 1.85</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Phoebe Buffay: Oh no.  Chandler Bing: What Richard thing? Phoebe Buffay: Simmons! Go with Simmons! Monica Geller: Okay, I umm, I ran into Richard yesterday and he asked me if I wanted to go for a bite and I did The only reason I didn't tell you is because I knew you'd get mad and I didn't want to spoil our anniversary Chandler Bing: I'm not mad Mon..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5><a href=\"https://blobstorages37d5t5m5wcyq.blob.core.windows.net/friends/s07/e02/c08.txt?sv=2022-11-02&ss=b&srt=sco&sp=rltfx&se=2025-10-10T11:14:44Z&st=2024-10-10T03:14:44Z&spr=https&sig=SR5VNDrPwrWJX4%2FphBxasF51p1x5Y85bf2Q%2FqcbJYLk%3D\">https://blobstorages37d5t5m5wcyq.blob.core.windows.net/friends/s07/e02/c08.txt</a> - score: 1.83</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Jack Geller: We started saving again when you were dating Richard and then that went to hell, so we redid the kitchen Monica Geller: What about when I started dating Chandler? Judy Geller: Well it was Chandler! We didn't think he'd ever propose! Chandler Bing: Clearly I did not start drinking enough at the start of the meal Monica Geller: I can't b..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5><a href=\"https://blobstorages37d5t5m5wcyq.blob.core.windows.net/friends/s05/e22/c01.txt?sv=2022-11-02&ss=b&srt=sco&sp=rltfx&se=2025-10-10T11:14:44Z&st=2024-10-10T03:14:44Z&spr=https&sig=SR5VNDrPwrWJX4%2FphBxasF51p1x5Y85bf2Q%2FqcbJYLk%3D\">https://blobstorages37d5t5m5wcyq.blob.core.windows.net/friends/s05/e22/c01.txt</a> - score: 1.78</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "That's all I ever hear, Richard, Richard, Richard! Monica Geller: Since we've been going out, I think I've mentioned his name twice! Chandler Bing: Okay, so Richard, Richard! Monica Geller: It's not Richard! Okay? It's this new guy and he's really good Rachel Green: Well, I'm sorry I'm not going to an eye doctor! Ross Geller: Oh God, here we go! Ch..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5><a href=\"https://blobstorages37d5t5m5wcyq.blob.core.windows.net/friends/s06/e25/c08.txt?sv=2022-11-02&ss=b&srt=sco&sp=rltfx&se=2025-10-10T11:14:44Z&st=2024-10-10T03:14:44Z&spr=https&sig=SR5VNDrPwrWJX4%2FphBxasF51p1x5Y85bf2Q%2FqcbJYLk%3D\">https://blobstorages37d5t5m5wcyq.blob.core.windows.net/friends/s06/e25/c08.txt</a> - score: 1.73</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Well, I'll just leave the door open and go sit on the couch Monica Geller: Chandler is such an idiot! Richard Burke: Drink? Monica Geller: Yeah, I'll have a scotch Richard Burke: ...on the rocks with a twist? I remember Monica Geller: Still smoking cigars? Richard Burke: Uh, no! No! That's...art! If it bothers you I can put my art out Monica Geller..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5><a href=\"https://blobstorages37d5t5m5wcyq.blob.core.windows.net/friends/s06/e24/c07.txt?sv=2022-11-02&ss=b&srt=sco&sp=rltfx&se=2025-10-10T11:14:44Z&st=2024-10-10T03:14:44Z&spr=https&sig=SR5VNDrPwrWJX4%2FphBxasF51p1x5Y85bf2Q%2FqcbJYLk%3D\">https://blobstorages37d5t5m5wcyq.blob.core.windows.net/friends/s06/e24/c07.txt</a> - score: 1.72</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "I'm Chandler! Oh, that's Richard! Monica Geller: Oh God, maybe he won't see us Richard!  unknown: nan  Richard Burke: Monica! Chandler! Chandler Bing: Hey-hey, hey! I don't know why I did that! Monica Geller: Hey, it's good to see you! Richard Burke: You too, you let uh, your hair grow long Monica Geller: Yeah-Oh that's right You, you always wanted..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML('<h4>Top Answers</h4>'))\n",
    "\n",
    "for index,search_results in agg_search_results.items():\n",
    "\n",
    "    for result in search_results['@search.answers']:\n",
    "        if result['score'] > 0.5: # Show answers that are at least 50% of the max possible score=1\n",
    "            display(HTML('<h5>' + 'Answer - score: ' + str(round(result['score'],2)) + '</h5>'))\n",
    "            display(HTML(result['text']))\n",
    "\n",
    "            \n",
    "print(\"\\n\\n\")\n",
    "display(HTML('<h4>Top Results</h4>'))\n",
    "\n",
    "content = dict()\n",
    "ordered_content = OrderedDict()\n",
    "\n",
    "\n",
    "for index,search_results in agg_search_results.items():\n",
    "    for result in search_results['value']:\n",
    "        if result['@search.rerankerScore'] > 1:# Show answers that are at least 25% of the max possible score=4\n",
    "            content[result['id']]={\n",
    "                                    \"title\": result['title'],\n",
    "                                    \"chunk\": result['chunk'], \n",
    "                                    \"name\": result['name'], \n",
    "                                    \"location\": result['location'] ,\n",
    "                                    \"caption\": result['@search.captions'][0]['text'],\n",
    "                                    \"score\": result['@search.rerankerScore'],\n",
    "                                    \"index\": index\n",
    "                                    }\n",
    "    \n",
    "#After results have been filtered we will Sort and add them as an Ordered list\\n\",\n",
    "for id in sorted(content, key= lambda x: content[x][\"score\"], reverse=True):\n",
    "    ordered_content[id] = content[id]\n",
    "    url = str(ordered_content[id]['location']) + os.environ['BLOB_SAS_TOKEN']\n",
    "    title = str(ordered_content[id]['title']) if (ordered_content[id]['title']) else ordered_content[id]['name']\n",
    "    score = str(round(ordered_content[id]['score'],2))\n",
    "    display(HTML('<h5><a href=\"'+ url + '\">' + ordered_content[id]['location'] + '</a> - score: '+ score + '</h5>'))\n",
    "    display(HTML(ordered_content[id]['caption']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a6d3e6-afb2-4fa7-96d3-69bc2373ded5",
   "metadata": {},
   "source": [
    "### Comments on Query results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e02227-6a92-4944-86f8-6c1e38d90fe4",
   "metadata": {},
   "source": [
    "As seen above the semantic re-ranking feature of Azure AI Search service is decent. It gives answers (sometimes) and also the top results with the corresponding file and the paragraph where the answers is possible located.\n",
    "\n",
    "Let's see if we can make this better with Azure OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df3e6d4-9a09-4b0f-b328-238738ccfaec",
   "metadata": {},
   "source": [
    "# Using Azure OpenAI\n",
    "\n",
    "To use OpenAI to get a better answer to our question, the thought process is simple: let's **give the answer and the content of the documents from the search result to the GPT model as context and let it provide a better response**. This is what RAG (Retreival Augmented Generation) is about.\n",
    "\n",
    "Now, before we do this, we need to understand a few things first:\n",
    "\n",
    "1) Chainning and Prompt Engineering\n",
    "2) Embeddings\n",
    "\n",
    "We will use a library call **LangChain** that wraps a lot of boiler plate code.\n",
    "Langchain is one library that does a lot of the prompt engineering for us under the hood, for more information see [here](https://python.langchain.com/docs/introduction/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eea62a7d-7e0e-4a93-a89c-20c96560c665",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
    "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325d9138-2250-4f6b-bc88-50d7957f8d33",
   "metadata": {},
   "source": [
    "**Important Note**: Starting now, we will utilize OpenAI models. Please ensure that you have deployed the following models within the Azure OpenAI portal:\n",
    "\n",
    "- text-embedding-ada-002 (or newer)\n",
    "- gpt-4o\n",
    "- gpt-4o-mini\n",
    "\n",
    "Reference for Azure OpenAI models (regions, limits, dimensions, etc): [HERE](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7c720e-ece1-45ad-9d01-2dfd15c182bb",
   "metadata": {},
   "source": [
    "## A gentle intro to chaining LLMs and prompt engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcd7028-5a6c-4296-8c85-4f420d408d69",
   "metadata": {},
   "source": [
    "Chains refer to sequences of calls - whether to an LLM, a tool, or a data preprocessing step.\n",
    "\n",
    "Azure OpenAI is a type of LLM (provider) that you can use but there are others like Cohere, Huggingface, etc.\n",
    "\n",
    "Chains can be simple (i.e. Generic) or specialized (i.e. Utility).\n",
    "\n",
    "* Generic — A single LLM is the simplest chain. It takes an input prompt and the name of the LLM and then uses the LLM for text generation (i.e. output for the prompt).\n",
    "\n",
    "Here’s an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13df9247-e784-4e04-9475-55e672efea47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "COMPLETION_TOKENS = 2000\n",
    "llm = AzureChatOpenAI(deployment_name=os.environ[\"GPT4oMINI_DEPLOYMENT_NAME\"], \n",
    "                      temperature=0, \n",
    "                      max_tokens=COMPLETION_TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3b55adb-6f98-4f15-b67a-9fbba5820560",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_parser = StrOutputParser()\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an assistant that give thorough responses to users.\"),\n",
    "    (\"user\", \"{input}. Give your response in {language}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6417d052-0035-4635-93e8-2bd3ec50d796",
   "metadata": {},
   "source": [
    "The | symbol is similar to a unix pipe operator, which chains together the different components feeds the output from one component as input into the next component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77a37e60-a1ef-4750-a1ec-9e4fe5ba07fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6be6b4df-ee2c-4a0c-8ad3-a672d70f4f8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Yes, Chandler does experience feelings of jealousy towards Richard in the TV show \"Friends.\" This jealousy primarily arises during the earlier seasons when Monica starts dating Richard, who is significantly older than her and has a more established life. Chandler, who has his own insecurities and struggles with commitment, feels threatened by Richard's maturity and the deep connection he shares with Monica.\n",
       "\n",
       "In particular, Chandler's jealousy is highlighted in episodes where he expresses concern about Monica's relationship with Richard, fearing that she might choose him over Chandler. This dynamic showcases Chandler's vulnerability and his desire for Monica's affection, ultimately leading to moments of tension and humor in the series. However, as the show progresses, Chandler's character grows more secure in his relationship with Monica, and the jealousy becomes less of a focal point."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.2 ms, sys: 3.68 ms, total: 33.9 ms\n",
      "Wall time: 1.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "display(Markdown(chain.invoke({\"input\": QUESTION, \"language\": \"English\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8539d0-a538-4368-82c3-5f91d8370f1e",
   "metadata": {},
   "source": [
    "**Note**: this is the first time you use OpenAI in this Accelerator, so if you get a Resource not found error, is most likely because the name of your OpenAI model deployment is different than the environmental variable set above `os.environ[\"GPT4oMINI_DEPLOYMENT_NAME\"]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ed014c-0c6b-448c-b995-fe7970b92ad5",
   "metadata": {},
   "source": [
    "Great!!, now you know how to create a simple prompt and use a chain in order to answer a general question using ChatGPT knowledge!. \n",
    "\n",
    "It is important to note that we rarely use generic chains as standalone chains. More often they are used as building blocks for Utility chains (as we will see next). Also important to notice is that we are NOT using our documents or the result of the Azure Search yet, just the knowledge of ChatGPT on the data it was trained on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c48038-b1af-4228-8ffb-720e554fd3b2",
   "metadata": {
    "tags": []
   },
   "source": [
    "**The second type of Chains are Utility:**\n",
    "\n",
    "* Utility — These are specialized chains, comprised of many building blocks to help solve a specific task. For example, LangChain supports some end-to-end chains (such as `create_retrieval_chain` for QnA Doc retrieval, Summarization, etc).\n",
    "\n",
    "We will build our own specific chain in this workshop for digging deeper and solve our use case of enhancing the results of Azure AI Search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0454ddb-44d8-4fa9-929a-5e5563dd28f8",
   "metadata": {},
   "source": [
    "\n",
    "But before dealing with the utility chain needed, let's first review the concept of Embeddings and Vector Search and RAG. \n",
    "\n",
    "## Embeddings and Vector Search\n",
    "\n",
    "From the Azure OpenAI documentation ([HERE](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/embeddings?tabs=python)), An embedding is a special format of data representation that can be easily utilized by machine learning models and algorithms. The embedding is an information dense representation of the semantic meaning of a piece of text. Each embedding is a vector of floating point numbers, such that the distance between two embeddings in the vector space is correlated with semantic similarity between two inputs in the original format. For example, if two texts are similar, then their vector representations should also be similar. \n",
    "\n",
    "### Why Do We Need Vectors?\n",
    "\n",
    "Vectors are essential for several reasons:\n",
    "\n",
    "- **Semantic Richness**: They convert the semantic meaning of text into mathematical vectors, capturing nuances that simple keyword searches miss. This makes them incredibly powerful for understanding and processing language.\n",
    "- **Human-like Searching**: Searching using vector distances mimics the human approach to finding information based on context and meaning, rather than relying solely on exact word matches.\n",
    "- **Efficiency in Scale**: Vector representations allow for efficient handling and searching of large datasets. By reducing complex text to numerical vectors, algorithms can quickly sift through vast amounts of information.\n",
    "\n",
    "### Understanding LLM Tokens' Context Limitation\n",
    "\n",
    "Large Language Models (LLMs) like GPT come with a token limit for each input, which poses a challenge when dealing with lengthy documents or extensive data sets. This limitation restricts the model's ability to understand and generate responses based on the full context of the information provided. It becomes crucial, therefore, to devise strategies that can effectively manage and circumvent this limitation to leverage the full power of LLMs.\n",
    "\n",
    "To address this challenge, the solution incorporates several key steps:\n",
    "\n",
    "1. **Segmenting Documents**: Breaking down large documents into smaller, manageable segments.\n",
    "2. **Vectorization of Chunks**: Converting these segments into vectors, making them compatible with vector-based search techniques.\n",
    "3. **Hybrid Search**: Employing both vector and text search methods to pinpoint the most relevant segments in relation to the query.\n",
    "4. **Optimal Context Provision**: Presenting the LLM with the most pertinent segments, ensuring a balance between detail and brevity to stay within token limits.\n",
    "\n",
    "\n",
    "Our ultimate goal is to rely solely on vector indexes and hybrid searchs (vector + text). While it is possible to manually code parsers with OCR for various file types and develop a scheduler to synchronize data with the index, there is a more efficient alternative: **Azure AI Search has automated chunking strategies and vectorization**.\n",
    "\n",
    "It's important to note that **document segmentation and vectorization have already been completed in AI Azure Search**, as seen in the `ordered_content` dictionary. This pre-processing step simplifies subsequent operations, ensuring rapid response times and adherence to the token limits of the chosen OpenAI model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e79235-3d8b-4713-9336-5004cc4a1556",
   "metadata": {},
   "source": [
    "So really, our only job now is to make sure that the results from the Azure AI Search queries fit on the LLM context size, and then let it do its magic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12682a1b-df92-49ce-a638-7277103f6cb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index_name = \"srch-index-files\"\n",
    "index2_name = \"srch-index-csv\"\n",
    "indexes = [index1_name, index2_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a6d6a7-18ef-45b2-a216-3c1f50006593",
   "metadata": {},
   "source": [
    "In order to not duplicate code, we have put many of the code used above into functions. These functions are in the `common/utils.py` and `common/prompts.py` files. This way we can use these functios in the app that we will build later.\n",
    "\n",
    "`get_search_results()` do the multi-index search and returns the combined ordered list of documents/chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bccca45-d1dd-476f-b109-a528b857b6b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of results: 20\n"
     ]
    }
   ],
   "source": [
    "k = 20  # play with this parameter and see the quality of the final answer\n",
    "ordered_results = get_search_results(QUESTION, indexes, k=k, reranker_threshold=1)\n",
    "print(\"Number of results:\",len(ordered_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7714f38a-daaa-4fc5-a95a-dd025d153216",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Uncomment the below line if you want to inspect the ordered results\n",
    "# ordered_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235d4238-df6e-40eb-ab38-4fe6db614acd",
   "metadata": {},
   "source": [
    "Now let's create a Prompt Template that will ground the response only in the chunks retrieve by our hybrid AI Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f86ed786-aca0-4e25-947b-d9cf3a82665c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question thoroughly, based **ONLY** on the following context:\n",
    "{context}\n",
    "\n",
    "Important: Assume you know nothing about the subject, only based your answer on the context above.\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25cba3d1-b5ab-4e28-96b3-ef923d99dc9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Yes, Chandler Bing does exhibit jealousy towards Richard Burke in the context provided. In one exchange, Chandler expresses his discomfort and jealousy regarding Monica's past relationship with Richard. He makes comments that suggest he is bothered by the idea of Monica being with Richard, indicating that he feels threatened by Richard's lingering feelings for Monica. For instance, Chandler mentions picturing Monica with Richard and makes a sarcastic remark about Richard keeping a tape of Monica, which implies that he is not entirely comfortable with Richard's presence in their lives. Additionally, Chandler's reaction to Richard's declaration of love for Monica further highlights his jealousy, as he feels that Richard is offering things that he himself is also willing to provide. Overall, Chandler's dialogue reflects a sense of jealousy and insecurity regarding Richard's relationship with Monica."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.8 ms, sys: 778 μs, total: 17.6 ms\n",
      "Wall time: 2.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# Creation of our custom chain\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "try:\n",
    "    display(Markdown(chain.invoke({\"question\": QUESTION, \"context\": ordered_results})))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417925af-486a-40bc-a290-28c35968c581",
   "metadata": {},
   "source": [
    "# Improving the Prompt and adding citations\n",
    "\n",
    "We could see above that in the answer given by GPT4o-mini, there is no citations or references. **How do we know if the answer is grounded on the context or not?**\n",
    "\n",
    "Let's see if this can be improved by Prompt Engineering.<br>\n",
    "On `common/prompts.py` we created a prompt called `DOCSEARCH_PROMPT_TEXT` check it out!\n",
    "\n",
    "**Let's also create a custom Retriever class** so we can plug it in easily within the chain building. \n",
    "Note: we can also use the Azure AI Search retriever class [HERE](https://python.langchain.com/docs/integrations/vectorstores/azuresearch), however we want to create a custom Retriever for the following reasons:\n",
    "\n",
    "1) We want to do multi-index searches in one call\n",
    "2) Easier to teach complex concepts of LangChain in this notebook\n",
    "3) We want to use the REST API vs the Python Azure Search SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bdf31f99-0dfb-423a-81f5-03018e61d9a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomRetriever(BaseRetriever):\n",
    "    \n",
    "    topK : int\n",
    "    reranker_threshold : int\n",
    "    indexes: List\n",
    "    sas_token: str = None\n",
    "    search_filter: str = None\n",
    "    \n",
    "    def _get_relevant_documents(self, query: str) -> List[dict]:\n",
    "        \n",
    "        ordered_results = get_search_results(query, self.indexes, k=self.topK, \n",
    "                                             reranker_threshold=self.reranker_threshold, \n",
    "                                             sas_token=self.sas_token, search_filter=self.search_filter)\n",
    "        top_docs = []\n",
    "        for key,value in ordered_results.items():\n",
    "            location = value[\"location\"] if value[\"location\"] is not None else \"\"\n",
    "            document = {\"source\": location,\n",
    "                        \"score\": value[\"score\"],\n",
    "                        \"page_content\": value[\"chunk\"]}\n",
    "            top_docs.append(document)\n",
    "\n",
    "        return top_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19b39c79-c827-4437-b58b-6a6fae53b968",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the retriever\n",
    "retriever = CustomRetriever(indexes=indexes, topK=k, reranker_threshold=1, sas_token=os.environ['BLOB_SAS_TOKEN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7aa4f58-4791-40a0-80c5-6582e0574579",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test retreiver\n",
    "results = retriever.invoke(QUESTION)\n",
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11b6546f-b5c5-4168-97fc-2636c50e41c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We can create now a dynamically configurable llm object that can change the model at runtime\n",
    "dynamic_llm = AzureChatOpenAI(deployment_name=os.environ[\"GPT4oMINI_DEPLOYMENT_NAME\"], \n",
    "                              temperature=0.5, max_tokens=COMPLETION_TOKENS).configurable_alternatives(\n",
    "    # This gives this field an id\n",
    "    # When configuring the end runnable, we can then use this id to configure this field\n",
    "    ConfigurableField(id=\"model\"),\n",
    "    # This sets a default_key.\n",
    "    # If we specify this key, the default LLM  (initialized above) will be used\n",
    "    default_key=\"gpt4omini\",\n",
    "    # This adds a new option, with name `gpt4o`\n",
    "    gpt4o=AzureChatOpenAI(deployment_name=os.environ[\"GPT4o_DEPLOYMENT_NAME\"], \n",
    "                         temperature=0.5, max_tokens=COMPLETION_TOKENS),\n",
    "    # You can add more configuration options here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0144dd4d-b5ff-4585-816a-fd1d0a93e544",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define prompt template\n",
    "DOCSEARCH_PROMPT = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", DOCSEARCH_PROMPT_TEXT + \"\\n\\nCONTEXT:\\n{context}\\n\\n\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7da2f31-cf5d-4f3a-aad5-67b50b56968e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Declaration of the chain with the dynamic llm and the new prompt\n",
    "configurable_chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | retriever, # Passes the question to the retriever and the results are assign to context\n",
    "        \"question\": itemgetter(\"question\")\n",
    "    }\n",
    "    | DOCSEARCH_PROMPT  # Passes the input variables above to the prompt template\n",
    "    | dynamic_llm   # Passes the finished prompt to the LLM\n",
    "    | StrOutputParser()  # converts the output (Runnable object) to the desired output (string)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b67200e5-d3ae-4c86-9f69-bc7b964ab532",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Yes, Chandler does exhibit jealousy towards Richard at times. For instance, in one conversation, Chandler expresses his discomfort and jealousy when he imagines Monica being intimate with Richard, stating, \"I just keep picturing you rolling around with him with your cowboy boots in the air\" [[1]](https://blobstorages37d5t5m5wcyq.blob.core.windows.net/friends/s09/e07/c11.txt?sv=2022-11-02&ss=b&srt=sco&sp=rltfx&se=2025-10-10T11:14:44Z&st=2024-10-10T03:14:44Z&spr=https&sig=SR5VNDrPwrWJX4%2FphBxasF51p1x5Y85bf2Q%2FqcbJYLk%3D). Additionally, Chandler's jealousy is further highlighted when he confronts Richard about his feelings for Monica, indicating that he feels insecure about his relationship with her compared to Richard [[1]](https://blobstorages37d5t5m5wcyq.blob.core.windows.net/friends/s09/e07/c11.txt?sv=2022-11-02&ss=b&srt=sco&sp=rltfx&se=2025-10-10T11:14:44Z&st=2024-10-10T03:14:44Z&spr=https&sig=SR5VNDrPwrWJX4%2FphBxasF51p1x5Y85bf2Q%2FqcbJYLk%3D)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.8 ms, sys: 5.22 ms, total: 40 ms\n",
      "Wall time: 6.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "try:\n",
    "    display(Markdown(configurable_chain.with_config(configurable={\"model\": \"gpt4omini\"}).invoke({\"question\": QUESTION})))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8661b48d-1e57-4a70-9b0a-cc59f9093267",
   "metadata": {},
   "source": [
    "As seen above, we were able to improve the quality and breath of the answer and add citations with only prompt engineering!\n",
    "\n",
    "#### Let's try again, but with GPT-4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "efcfac6b-bac2-40c6-9ded-e4ee38e3093f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Yes, Chandler is jealous of Richard on multiple occasions. Here are some examples:\n",
       "\n",
       "1. **Tape Incident**: Chandler is jealous when he finds a tape that he mistakenly believes features Monica and Richard. He expresses his insecurity about Richard still having feelings for Monica and keeping the tape to watch it whenever he wants [[1]](https://blobstorages37d5t5m5wcyq.blob.core.windows.net/friends/s09/e07/c11.txt?sv=2022-11-02&ss=b&srt=sco&sp=rltfx&se=2025-10-10T11:14:44Z&st=2024-10-10T03:14:44Z&spr=https&sig=SR5VNDrPwrWJX4%2FphBxasF51p1x5Y85bf2Q%2FqcbJYLk%3D).\n",
       "\n",
       "2. **Anniversary Dinner**: Chandler and Monica run into Richard at a restaurant, and Chandler becomes visibly uncomfortable and awkward. He even makes jokes to mask his discomfort [[2]](https://blobstorages37d5t5m5wcyq.blob.core.windows.net/friends/s06/e24/c07.txt?sv=2022-11-02&ss=b&srt=sco&sp=rltfx&se=2025-10-10T11:14:44Z&st=2024-10-10T03:14:44Z&spr=https&sig=SR5VNDrPwrWJX4%2FphBxasF51p1x5Y85bf2Q%2FqcbJYLk%3D).\n",
       "\n",
       "3. **Richard's Proposal**: When Chandler finds out that Richard confessed his love to Monica and expressed his desire to marry her, he becomes extremely anxious and feels threatened. This incident culminates in Chandler expressing his frustration and fear that Monica might choose Richard over him [[3]](https://blobstorages37d5t5m5wcyq.blob.core.windows.net/friends/s06/e25/c11.txt?sv=2022-11-02&ss=b&srt=sco&sp=rltfx&se=2025-10-10T11:14:44Z&st=2024-10-10T03:14:44Z&spr=https&sig=SR5VNDrPwrWJX4%2FphBxasF51p1x5Y85bf2Q%2FqcbJYLk%3D).\n",
       "\n",
       "These instances clearly show Chandler's jealousy towards Richard throughout the series."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38.3 ms, sys: 1.52 ms, total: 39.8 ms\n",
      "Wall time: 9.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "try:\n",
    "    display(Markdown(configurable_chain.with_config(configurable={\"model\": \"gpt4o\"}).invoke({\"question\": QUESTION})))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c791651-2c56-4de7-a232-8ff94937b938",
   "metadata": {},
   "source": [
    "**Answers from GPT-4o-mini and GPT-4o can vary ever time you run it!, and they are all correct most of the time**\n",
    "\n",
    "However if you try many times, you will see that GPT-4o provide better answers and is better at following instructions and citations and it is less prune to hallucinate. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6690453b-a9b1-4907-bd43-8c6b3ecba26e",
   "metadata": {},
   "source": [
    "## Adding Streaming to improve user experience and performance\n",
    "\n",
    "One way to make the response look faster is to stream the answer, so the user can see the response as it is typed. To do this, we just simply need to call the method `stream` instead of `invoke`. More on Streaming and Callbacks in later notebooks, but for now, this is one simple way to do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d250c88-5984-438f-8390-1d93756048ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, Chandler does experience jealousy towards Richard on multiple occasions. Here are some instances:\n",
      "\n",
      "1. **Tape Incident**: Chandler is upset when he finds a tape at Richard's apartment that he believes contains a recording of Monica and Richard together. He expresses his insecurity by comparing himself to Richard, whom he views as more mature and capable of handling such things without being bothered. Chandler's jealousy is evident when he says, \"This is about you and Richard. He's clearly not over you. He keeps a tape so he can... look at it whenever he wants\" [[1]](https://blobstorages37d5t5m5wcyq.blob.core.windows.net/friends/s09/e07/c11.txt?sv=2022-11-02&ss=b&srt=sco&sp=rltfx&se=2025-10-10T11:14:44Z&st=2024-10-10T03:14:44Z&spr=https&sig=SR5VNDrPwrWJX4%2FphBxasF51p1x5Y85bf2Q%2FqcbJYLk%3D).\n",
      "\n",
      "2. **Anniversary Dinner**: Chandler is jealous when Monica runs into Richard and has dinner with him. Although Chandler initially pretends not to be mad, his true feelings are revealed when he sarcastically remarks, \"Oh yeah! Yeah, so you-you bumped into Richard! You grabbed a bite! It’s no big deal\" [[2]](https://blobstorages37d5t5m5wcyq.blob.core.windows.net/friends/s05/e23/c03.txt?sv=2022-11-02&ss=b&srt=sco&sp=rltfx&se=2025-10-10T11:14:44Z&st=2024-10-10T03:14:44Z&spr=https&sig=SR5VNDrPwrWJX4%2FphBxasF51p1x5Y85bf2Q%2FqcbJYLk%3D).\n",
      "\n",
      "3. **Proposal Plan**: Chandler's jealousy peaks when Richard confesses his love to Monica and expresses his desire to marry her. Chandler confronts Richard, saying, \"Nothing happened? Nothing? So you didn’t tell my girlfriend that you love her?\" and later exclaims his frustration that Richard made Monica think about their relationship [[3]](https://blobstorages37d5t5m5wcyq.blob.core.windows.net/friends/s06/e25/c11.txt?sv=2022-11-02&ss=b&srt=sco&sp=rltfx&se=2025-10-10T11:14:44Z&st=2024-10-10T03:14:44Z&spr=https&sig=SR5VNDrPwrWJX4%2FphBxasF51p1x5Y85bf2Q%2FqcbJYLk%3D).\n",
      "\n",
      "These instances clearly show that Chandler feels threatened by Richard's past relationship with Monica and is jealous of the connection they once shared."
     ]
    }
   ],
   "source": [
    "for chunk in configurable_chain.with_config(configurable={\"model\": \"gpt4o\"}).stream({\"question\": QUESTION}):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487bf690-3398-4824-96bc-b28e4da7e524",
   "metadata": {},
   "source": [
    "## Testing Groundness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcb4f9e-4fec-4e23-8d89-be0cf900e34d",
   "metadata": {},
   "source": [
    "Let’s ask the same question again, but this time for Season 1, where we know Richard doesn’t appear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad7644c3-e92e-4e6c-9a3e-a64f6f036be8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "search_filter = \"substringof('/s01/', location)\"\n",
    "retriever = CustomRetriever(indexes=indexes, topK=k, reranker_threshold=1, \n",
    "                            sas_token=os.environ['BLOB_SAS_TOKEN'],\n",
    "                            search_filter=search_filter)\n",
    "configurable_chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | retriever, # Passes the question to the retriever and the results are assign to context\n",
    "        \"question\": itemgetter(\"question\")\n",
    "    }\n",
    "    | DOCSEARCH_PROMPT  # Passes the input variables above to the prompt template\n",
    "    | dynamic_llm   # Passes the finished prompt to the LLM\n",
    "    | StrOutputParser()  # converts the output (Runnable object) to the desired output (string)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "69e78ed8-e03e-4b9b-a9d6-d4fbd9563b66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Empty Search Response\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The tools did not provide relevant information. I cannot answer this from prior knowledge."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.6 ms, sys: 3.39 ms, total: 39 ms\n",
      "Wall time: 1.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "try:\n",
    "    display(Markdown(configurable_chain.with_config(configurable={\"model\": \"gpt4o\"}).invoke({\"question\": QUESTION})))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778c84a9-d4bc-44f0-9270-2896e756e14c",
   "metadata": {},
   "source": [
    "**Perfect!**, even know the model knows the answer based on its training data, it is grounding the answer only on the results from the context retrieved from azure AI search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f347373a-a5be-473d-b64e-0f6b6dbcd0e0",
   "metadata": {},
   "source": [
    "# Summary\n",
    "##### By using OpenAI, the answers to user questions are way better than taking just the results from Azure AI Search. So the summary is:\n",
    "- Utilizing Azure AI Search, we conduct a multi-index hybrid search that identifies the top chunks of documents from each index.\n",
    "- Subsequently, Azure OpenAI utilizes these extracted chunks as context, comprehends the content, and employs it to deliver optimal answers.\n",
    "- Best of two worlds!\n",
    "\n",
    "##### Important observations on this notebook:\n",
    "\n",
    "1) Answers with GPT-4o-mini and GPT-4o are both correct, but GPT-4o seems have more breath and depth on its answers.\n",
    "2) Both models provide good and diverse citations in the right format.\n",
    "3) Streaming the answers improves the user experience big time!\n",
    "4) We achieved a good level of groundness using prompt engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc6e2fe-1c34-4952-99ad-14940f022379",
   "metadata": {},
   "source": [
    "# NEXT\n",
    "In the next notebook, we are going to see how we can treat complex and large documents separately, also using Vector Search"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
